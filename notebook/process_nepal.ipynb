{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapefile as shp\n",
    "import osmnx as ox\n",
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D  # for legend handle\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Proj, transform\n",
    "import math\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/configs/nepal/data_setup.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m config_reader \u001b[38;5;241m=\u001b[39m ConfigReader()\n\u001b[1;32m      9\u001b[0m config_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigs/nepal/data_setup.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m config_data \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_configuration_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_directory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconfig_file_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m config_data\n",
      "File \u001b[0;32m~/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/src/utils/config_reader.py:9\u001b[0m, in \u001b[0;36mConfigReader.read_configuration_file\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_configuration_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     10\u001b[0m         config_data \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_data\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/configs/nepal/data_setup.yaml'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "base_directory = \"/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/\"\n",
    "sys.path.append(f\"{base_directory}\")\n",
    "\n",
    "\n",
    "from src.utils.config_reader import ConfigReader\n",
    "\n",
    "config_reader = ConfigReader()\n",
    "config_file_path = \"configs/nepal/data_setup.yaml\"\n",
    "config_data = config_reader.read_configuration_file(f\"{base_directory}{config_file_path}\")\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_exposure_config = None\n",
    "for process in config_data['processing']:\n",
    "    if process['type'] == 'Population Exposure Calculation':\n",
    "        population_exposure_config = process\n",
    "\n",
    "df_population = pd.read_csv(f\"{base_directory}{population_exposure_config['population_source']}\")\n",
    "\n",
    "df_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/nepal/inputs/pga_475y.tif\"\n",
    "input_path2 = \"../data/nepal/inputs/pga_specifications.xlsx\"\n",
    "# input_path2 = \"../data/nepal/inputs/pga_specifications.tsv\"\n",
    "# input_path2 = \"../data/nepal/inputs/pga_specifications.csv\"\n",
    "output_path = \"../data/nepal/outputs/map/Peak_Ground_Acceleration.gpkg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre el archivo TIF\n",
    "with rasterio.open(input_path) as src:\n",
    "    # Imprime información sobre el archivo\n",
    "    print(src.profile)\n",
    "\n",
    "    # Lee todas las bandas y guarda los valores en una matriz\n",
    "    data = src.read()\n",
    "\n",
    "    # Imprime el número de bandas y el tamaño de la matriz\n",
    "    print(f'Número de bandas: {src.count}')\n",
    "    print(f'Tamaño de la matriz: {data.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para transformar las coordenadas de los píxeles a coordenadas de mapa\n",
    "def pixel_to_map_coordinates(transform, col, row):\n",
    "    x, y = transform * (col, row)\n",
    "    return x, y\n",
    "\n",
    "# Abrir el archivo TIF\n",
    "with rasterio.open(input_path) as src:\n",
    "    # Leer todas las bandas y guardar los valores en una matriz\n",
    "    data = src.read()\n",
    "\n",
    "    # Obtener la transformación de coordenadas de píxeles a coordenadas de mapa\n",
    "    transform = src.transform\n",
    "\n",
    "    # Crear una lista vacía para almacenar los datos de cada polígono\n",
    "    polygons = []\n",
    "\n",
    "    # Iterar sobre cada banda y crear polígonos para cada píxel con valor distinto de cero\n",
    "    for i in range(src.count):\n",
    "        band_data = data[i, :, :]\n",
    "\n",
    "        for row in tqdm(range(band_data.shape[0])):\n",
    "            for col in range(band_data.shape[1]):\n",
    "                # Obtener el valor del píxel\n",
    "                value = band_data[row, col]\n",
    "\n",
    "                # Si el valor es cero, ignorar el píxel\n",
    "                if value > 0:\n",
    "                    #continue\n",
    "\n",
    "                    # Calcular las coordenadas de los cuatro vértices del polígono\n",
    "                    x1, y1 = pixel_to_map_coordinates(transform, col, row)\n",
    "                    x2, y2 = pixel_to_map_coordinates(transform, col + 1, row)\n",
    "                    x3, y3 = pixel_to_map_coordinates(transform, col + 1, row + 1)\n",
    "                    x4, y4 = pixel_to_map_coordinates(transform, col, row + 1)\n",
    "\n",
    "                    # Crear el polígono a partir de los vértices\n",
    "                    poly = Polygon([(x1, y1), (x2, y2), (x3, y3), (x4, y4)])\n",
    "\n",
    "                    # Agregar el polígono y su información a la lista de polígonos\n",
    "                    polygon_data = {\n",
    "                        'band': i+1,\n",
    "                        'value': value,\n",
    "                        'geometry': poly\n",
    "                    }\n",
    "                    polygons.append(polygon_data)\n",
    "                    \n",
    "# Crear un GeoDataFrame a partir de la lista de polígonos\n",
    "gdf = gpd.GeoDataFrame(polygons)\n",
    "\n",
    "# Agregar el polígono y su información\n",
    "pga_specifications = pd.read_csv(f\"{input_path2}\", delimiter='\\t')\n",
    "\n",
    "gdf.to_file(output_path, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the GeoDataFrame with colors based on the 'value' column\n",
    "gdf.plot(column='value', cmap='viridis', legend=True, figsize=(10, 10))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Map with Colors per Value Column')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pga_specifications = pd.read_csv(f\"{input_path2}\", delimiter='\\t')\n",
    "\n",
    "pga_specifications = pd.read_excel(f\"{input_path2}\")  \n",
    "\n",
    "# dtype_mapping = {\n",
    "#     'Acceleration_min': float,\n",
    "#     'Acceleration_max': float, \n",
    "# }\n",
    "\n",
    "# pga_specifications = pd.read_csv(f\"{input_path2}\", dtype=dtype_mapping)\n",
    "pga_specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pga_specifications.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrumental_Intensity             I\n",
    "# Acceleration_g            < 0.000464\n",
    "# Acceleration_min                -1.0\n",
    "# Acceleration_max            0.000464\n",
    "# Velocity_cmxs               < 0.0215\n",
    "# Perceived_shaking           Not felt\n",
    "# Potential_damage                 NaN\n",
    "# Name: 0, dtype: object\n",
    "\n",
    "def identify_interval(value, df, min_col, max_col):\n",
    "    for index, row in df.iterrows():\n",
    "        min_value = row[min_col]\n",
    "        max_value = row[max_col]\n",
    "        if min_value <= value and value < max_value:\n",
    "            return row['Instrumental_Intensity'], row['Acceleration_g'], row['Velocity_cmxs'], row['Perceived_shaking'], row['Potential_damage']\n",
    "    \n",
    "    \n",
    "\n",
    "def gdf_interval_df(gdf, df, value_col, min_col, max_col):\n",
    "    '''\n",
    "    '''\n",
    "    gdf2 = gdf.copy()\n",
    "    resultado = gdf2.apply(lambda x: identify_interval(x[value_col], df, min_col, max_col), axis=1)\n",
    "    gdf2['Instrumental_Intensity'] = [x[0] for x in resultado]\n",
    "    gdf2['Acceleration_g'] = [x[1] for x in resultado]\n",
    "    gdf2['Velocity_cmxs'] = [x[2] for x in resultado]\n",
    "    gdf2['Perceived_shaking'] = [x[3] for x in resultado]\n",
    "    gdf2['Potential_damage'] = [x[4] for x in resultado]\n",
    "\n",
    "    return gdf2\n",
    "\n",
    "gdf2 = gdf_interval_df(gdf, pga_specifications, value_col='value', min_col='Acceleration_min', max_col='Acceleration_max')\n",
    "gdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(gdf2['Instrumental_Intensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_geodataframe: comenzar con hospitales y earthquake\n",
    "\n",
    "para hospital: \n",
    "        id \n",
    "        nombre \n",
    "        geometria\n",
    "        costo de reparacion\n",
    "        recontruccion coste\n",
    "        admin level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# def exposure (hazards_geodataframe, assets_geodataframe, substantial_damage, complete_destruction=None):\n",
    "#     '''\n",
    "#     hazards_geodataframe: \n",
    "#     assets_geodataframe: dataframde infraestucturas puntos geometricos, lineas, o polygonos (son las infraestruturas)\n",
    "#     '''\n",
    "    \n",
    "#     # if complete_destruction\n",
    "#         # ver que polygonos:  substacia_damage <= X < complete_destruction\n",
    "#             hazards_geodataframe_filtrado_substantial_damage\n",
    "    \n",
    "#             hazards_geodataframe_filtrado_complete_destruction (# >= complete_destruction)\n",
    "#     # else\n",
    "#         # ver que polygonos estan dentro de substacia damage (>=)\n",
    "        \n",
    "#         hazards_geodataframe_filtrado_substantial_damage\n",
    "        \n",
    "    \n",
    "#     assets_geodataframe:    damage_level (0.5, or 1) \n",
    "        \n",
    "    \n",
    "#     return \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
