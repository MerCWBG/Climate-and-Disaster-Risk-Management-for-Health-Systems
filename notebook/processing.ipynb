{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "base_directory = \"/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/\"\n",
    "sys.path.append(f\"{base_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config_reader import ConfigReader, Logger\n",
    "from src.utils.utils import GeoDataFrameOperations\n",
    "from src.utils.file_pocessor import FileLister, FileProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Logger\n",
    "log_directory = \"/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/data/nepal/outputs/log\"\n",
    "log_file_name = \"processing\"\n",
    "logger = Logger(log_directory, log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Content of /Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/config/nepal/data_setup.yaml file successfully read\n"
     ]
    }
   ],
   "source": [
    "# Readding the configuration file to the preprocessing\n",
    "config_file_path = \"config/nepal/data_setup.yaml\"\n",
    "config_file_path = f\"{base_directory}{config_file_path}\"\n",
    "\n",
    "try:\n",
    "    config_data = ConfigReader.read_yaml_file(config_file_path)\n",
    "    # config_data = config_data['processing']\n",
    "    txt_msg = \"Content of {} file successfully read\".format(config_file_path)\n",
    "    logger.info(txt_msg)\n",
    "except Exception as e:\n",
    "    txt_msg = f\"Error reading configuration file: {str(e)}\"\n",
    "    logger.error(txt_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Administrative region\n",
    "path_map = f\"{base_directory}{config_data['adminitrative_maps']}\"\n",
    "data_map = FileProcessor.read_geopackage(path_map)\n",
    "\n",
    "# Hazards list files\n",
    "path_hazards = f\"{base_directory}{config_data['preprocessed_hazards']}\"\n",
    "data_hazards = FileLister.list_files(path_hazards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exposure_in_points(object_file, hazard_files):\n",
    "    data_object = FileProcessor.read_geopackage(object_file)\n",
    "    data_object = data_object.reset_index(drop=False)\n",
    "    data_object = data_object.rename(columns={'index': 'temp_index'})\n",
    "    data_object_temp = data_object[['temp_index','geometry']]\n",
    "    data_exposure = data_object_temp.copy()\n",
    "    for file in hazard_files:\n",
    "        hazard_name = file[0]\n",
    "        print(hazard_name)\n",
    "        data_hazard = FileProcessor.read_geopackage(file[1])\n",
    "        data_hazard = data_hazard.rename(columns={'damage': hazard_name})\n",
    "        data_hazard = gpd.sjoin(data_object_temp, data_hazard, how='left', predicate='intersects')\n",
    "        data_hazard[hazard_name] = data_hazard[hazard_name].fillna('no damage')\n",
    "        data_hazard = data_hazard[['temp_index', hazard_name]]\n",
    "        data_exposure = gpd.GeoDataFrame.merge(data_exposure, data_hazard, on='temp_index', suffixes=('', '_gdf2'))\n",
    "        del data_hazard\n",
    "    del data_object_temp\n",
    "    del data_exposure['geometry']\n",
    "    data_exposure = gpd.GeoDataFrame.merge(data_object, data_exposure, on='temp_index', suffixes=('', '_gdf2'))\n",
    "    del data_exposure['temp_index']\n",
    "    return data_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prosessing: population_4326\n",
      "earthquakes_period_475\n",
      "landslides_historical\n",
      "earthquakes_period_1500\n",
      "earthquakes_period_2475\n",
      "earthquakes_period_975\n",
      "Prosessing: healt_facilities_infrastructure\n",
      "earthquakes_period_475\n",
      "landslides_historical\n",
      "earthquakes_period_1500\n",
      "earthquakes_period_2475\n",
      "earthquakes_period_975\n",
      "Prosessing: PHC_infrastructure\n",
      "earthquakes_period_475\n",
      "landslides_historical\n",
      "earthquakes_period_1500\n",
      "earthquakes_period_2475\n",
      "earthquakes_period_975\n"
     ]
    }
   ],
   "source": [
    "# Task_list\n",
    "path_taks_results = f\"{base_directory}{config_data['processing']['output_file']}\"\n",
    "# print(path_taks_results)\n",
    "# resultado = None\n",
    "# resultado2 = None\n",
    "for task in config_data['processing']['tasks']:\n",
    "    task_name = task['name']\n",
    "    task_type = task['type']\n",
    "    \n",
    "    if task_type == \"exposure_population\":\n",
    "        path_populations = f\"{base_directory}{task['population_sources']}\"\n",
    "        data_populations = FileLister.list_files(path_populations)\n",
    "        for object_file in data_populations:\n",
    "            object_name = object_file[0]\n",
    "            object_file = object_file[1]\n",
    "            print(f'Prosessing: {object_name}')\n",
    "            data_exposure = compute_exposure_in_points(object_file, data_hazards)\n",
    "            columns_to_keep = [x for x in data_exposure.columns if x not in data_map.columns] + ['geometry']\n",
    "            data_exposure = gpd.sjoin(data_exposure[columns_to_keep], data_map, how='left', predicate='intersects')\n",
    "            del data_exposure['index_right']\n",
    "            output_name = f'{task_type}_{object_name}.gpkg'\n",
    "            FileProcessor.save_to_geopackage(data_exposure, path_taks_results, output_name)\n",
    "        pass\n",
    "    \n",
    "    if task_type == \"exposure_infrastructure\":\n",
    "        path_infrastructures = f\"{base_directory}{task['infrastructures_sources']}\"\n",
    "        data_infrastructures = FileLister.list_files(path_infrastructures)\n",
    "        resultado = data_infrastructures\n",
    "        for object_file in data_infrastructures:\n",
    "            object_name = object_file[0]\n",
    "            object_file = object_file[1]\n",
    "            print(f'Prosessing: {object_name}')\n",
    "            data_exposure = compute_exposure_in_points(object_file, data_hazards)\n",
    "            columns_to_keep = [x for x in data_exposure.columns if x not in data_map.columns] + ['geometry']\n",
    "            data_exposure = gpd.sjoin(data_exposure[columns_to_keep], data_map, how='left', predicate='intersects')\n",
    "            del data_exposure['index_right']\n",
    "            output_name = f'{task_type}_{object_name}.gpkg'\n",
    "            FileProcessor.save_to_geopackage(data_exposure, path_taks_results, output_name)\n",
    "    \n",
    "    if task_type == \"risk_index\":\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GHFD_ID', 'HF_ID_N', 'HF_N_RO', 'HF_N_LOC', 'HF_T_RO', 'HF_T_LO',\n",
       "       'HF_OWN', 'HF_ADD_STR', 'HF_ADD_NO', 'HF_ADD_PC', 'HF_ADD_CN', 'LAT',\n",
       "       'LONG', 'S_COOR', 'M_COOR', 'AC_COOR', 'earthquakes_period_475',\n",
       "       'geometry', 'index_right', 'ADM1_C', 'ADM1_N_RO', 'ADM2_C', 'ADM2_N_RO',\n",
       "       'ADM3_C', 'ADM3_N_RO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exposure.head()\n",
    "data_exposure.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prosessing exposure_infrastructure_healt_facilities_infrastructure ...\n",
      "Prosessing exposure_infrastructure_PHC_infrastructure ...\n"
     ]
    }
   ],
   "source": [
    "# Task_list\n",
    "path_taks_results = f\"{base_directory}{config_data['processing']['output_file']}\"\n",
    "files_results = FileLister.list_files(path_taks_results)\n",
    "\n",
    "for file_result in files_results[:2]:\n",
    "    file_name = file_result[0]\n",
    "    file_result = file_result[1]\n",
    "    print(f'Prosessing {file_name} ...')\n",
    "    data_result = FileProcessor.read_geopackage(file_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHFD_ID</th>\n",
       "      <th>HF_ID_N</th>\n",
       "      <th>HF_N_RO</th>\n",
       "      <th>HF_N_LOC</th>\n",
       "      <th>HF_T_RO</th>\n",
       "      <th>HF_T_LO</th>\n",
       "      <th>HF_OWN</th>\n",
       "      <th>HF_ADD_STR</th>\n",
       "      <th>HF_ADD_NO</th>\n",
       "      <th>HF_ADD_PC</th>\n",
       "      <th>...</th>\n",
       "      <th>earthquakes_period_2475</th>\n",
       "      <th>earthquakes_period_975</th>\n",
       "      <th>index_right</th>\n",
       "      <th>ADM1_C_right</th>\n",
       "      <th>ADM1_N_RO_right</th>\n",
       "      <th>ADM2_C_right</th>\n",
       "      <th>ADM2_N_RO_right</th>\n",
       "      <th>ADM3_C_right</th>\n",
       "      <th>ADM3_N_RO_right</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aadhaebhut Swastha Kendra</td>\n",
       "      <td>None</td>\n",
       "      <td>Primary Health Care Center</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>155</td>\n",
       "      <td>NPL-ADM1-38925275B31954132</td>\n",
       "      <td>Province 2</td>\n",
       "      <td>NPL-ADM2-48590121B79767844</td>\n",
       "      <td>SAPTARI</td>\n",
       "      <td>NPL-ADM3-92635248B74966006</td>\n",
       "      <td>Tilathi Koiladi</td>\n",
       "      <td>POINT (86.81394 26.49696)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aadharbhut Swastha Sewa Kendra</td>\n",
       "      <td>None</td>\n",
       "      <td>Primary Health Care Center</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>155</td>\n",
       "      <td>NPL-ADM1-38925275B31954132</td>\n",
       "      <td>Province 2</td>\n",
       "      <td>NPL-ADM2-48590121B79767844</td>\n",
       "      <td>SAPTARI</td>\n",
       "      <td>NPL-ADM3-92635248B74966006</td>\n",
       "      <td>Tilathi Koiladi</td>\n",
       "      <td>POINT (86.82662 26.51304)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aadharbhut Swasthya Sewa Kendra Chhadekholaa</td>\n",
       "      <td>आधारभूत स्वास्थ्य सेवा केन्द्र छदेखोला</td>\n",
       "      <td>Primary Health Care Center</td>\n",
       "      <td>None</td>\n",
       "      <td>Local Government</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>617</td>\n",
       "      <td>NPL-ADM1-38925275B17766335</td>\n",
       "      <td>Karnali</td>\n",
       "      <td>NPL-ADM2-48590121B24358344</td>\n",
       "      <td>DAILEKH</td>\n",
       "      <td>NPL-ADM3-92635248B3555706</td>\n",
       "      <td>Chamunda Bindrasaini</td>\n",
       "      <td>POINT (81.54452 28.93257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aadharubhut Swaasthya Sewa Kendra</td>\n",
       "      <td>आधारभूत स्वास्थ्य सेव केन्द्र</td>\n",
       "      <td>Primary Health Care Center</td>\n",
       "      <td>None</td>\n",
       "      <td>Local Government</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>617</td>\n",
       "      <td>NPL-ADM1-38925275B17766335</td>\n",
       "      <td>Karnali</td>\n",
       "      <td>NPL-ADM2-48590121B24358344</td>\n",
       "      <td>DAILEKH</td>\n",
       "      <td>NPL-ADM3-92635248B3555706</td>\n",
       "      <td>Chamunda Bindrasaini</td>\n",
       "      <td>POINT (81.50951 28.90983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aahal Dada Urban Health Center  UHC</td>\n",
       "      <td>None</td>\n",
       "      <td>Primary Health Care Center</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>substantial damage</td>\n",
       "      <td>327</td>\n",
       "      <td>NPL-ADM1-38925275B3223679</td>\n",
       "      <td>Bagmati</td>\n",
       "      <td>NPL-ADM2-48590121B615949</td>\n",
       "      <td>DHADING</td>\n",
       "      <td>NPL-ADM3-92635248B55308155</td>\n",
       "      <td>Nilakantha</td>\n",
       "      <td>POINT (84.97833 27.90778)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  GHFD_ID HF_ID_N                                       HF_N_RO  \\\n",
       "0    None    None                     Aadhaebhut Swastha Kendra   \n",
       "1    None    None                Aadharbhut Swastha Sewa Kendra   \n",
       "2    None    None  Aadharbhut Swasthya Sewa Kendra Chhadekholaa   \n",
       "3    None    None             Aadharubhut Swaasthya Sewa Kendra   \n",
       "4    None    None           Aahal Dada Urban Health Center  UHC   \n",
       "\n",
       "                                 HF_N_LOC                     HF_T_RO HF_T_LO  \\\n",
       "0                                    None  Primary Health Care Center    None   \n",
       "1                                    None  Primary Health Care Center    None   \n",
       "2  आधारभूत स्वास्थ्य सेवा केन्द्र छदेखोला  Primary Health Care Center    None   \n",
       "3           आधारभूत स्वास्थ्य सेव केन्द्र  Primary Health Care Center    None   \n",
       "4                                    None  Primary Health Care Center    None   \n",
       "\n",
       "             HF_OWN HF_ADD_STR HF_ADD_NO HF_ADD_PC  ...  \\\n",
       "0              None       None      None      None  ...   \n",
       "1              None       None      None      None  ...   \n",
       "2  Local Government       None      None      None  ...   \n",
       "3  Local Government       None      None      None  ...   \n",
       "4              None       None      None      None  ...   \n",
       "\n",
       "  earthquakes_period_2475  earthquakes_period_975  index_right  \\\n",
       "0      substantial damage      substantial damage          155   \n",
       "1      substantial damage      substantial damage          155   \n",
       "2      substantial damage      substantial damage          617   \n",
       "3      substantial damage      substantial damage          617   \n",
       "4      substantial damage      substantial damage          327   \n",
       "\n",
       "                 ADM1_C_right ADM1_N_RO_right                ADM2_C_right  \\\n",
       "0  NPL-ADM1-38925275B31954132      Province 2  NPL-ADM2-48590121B79767844   \n",
       "1  NPL-ADM1-38925275B31954132      Province 2  NPL-ADM2-48590121B79767844   \n",
       "2  NPL-ADM1-38925275B17766335         Karnali  NPL-ADM2-48590121B24358344   \n",
       "3  NPL-ADM1-38925275B17766335         Karnali  NPL-ADM2-48590121B24358344   \n",
       "4   NPL-ADM1-38925275B3223679         Bagmati    NPL-ADM2-48590121B615949   \n",
       "\n",
       "  ADM2_N_RO_right                ADM3_C_right       ADM3_N_RO_right  \\\n",
       "0         SAPTARI  NPL-ADM3-92635248B74966006       Tilathi Koiladi   \n",
       "1         SAPTARI  NPL-ADM3-92635248B74966006       Tilathi Koiladi   \n",
       "2         DAILEKH   NPL-ADM3-92635248B3555706  Chamunda Bindrasaini   \n",
       "3         DAILEKH   NPL-ADM3-92635248B3555706  Chamunda Bindrasaini   \n",
       "4         DHADING  NPL-ADM3-92635248B55308155            Nilakantha   \n",
       "\n",
       "                    geometry  \n",
       "0  POINT (86.81394 26.49696)  \n",
       "1  POINT (86.82662 26.51304)  \n",
       "2  POINT (81.54452 28.93257)  \n",
       "3  POINT (81.50951 28.90983)  \n",
       "4  POINT (84.97833 27.90778)  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config_reader import ConfigReader\n",
    "\n",
    "config_reader = ConfigReader()\n",
    "config_file_path = \"config/nepal/setup_preprocessing.yaml\"\n",
    "config_data = config_reader.read_configuration_file(f\"{base_directory}{config_file_path}\")\n",
    "config_data = config_data['preprocessing']\n",
    "\n",
    "# population_exposure_config = None\n",
    "# for task in config_data:\n",
    "#     print(task)\n",
    "    \n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapefile as shp\n",
    "import osmnx as ox\n",
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D  # for legend handle\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Proj, transform\n",
    "import math\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"../src\"))\n",
    "# import functions_support as fsupport\n",
    "\n",
    "import importlib\n",
    "\n",
    "# importlib.reload(fsupport)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/nepal/inputs/pga_475y.tif\"\n",
    "input_path2 = \"../data/nepal/inputs/pga_specifications.xlsx\"\n",
    "output_path = \"../data/nepal/outputs/map/Peak_Ground_Acceleration.gpkg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre el archivo TIF\n",
    "with rasterio.open(input_path) as src:\n",
    "    # Imprime información sobre el archivo\n",
    "    print(src.profile)\n",
    "\n",
    "    # Lee todas las bandas y guarda los valores en una matriz\n",
    "    data = src.read()\n",
    "\n",
    "    # Imprime el número de bandas y el tamaño de la matriz\n",
    "    print(f'Número de bandas: {src.count}')\n",
    "    print(f'Tamaño de la matriz: {data.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para transformar las coordenadas de los píxeles a coordenadas de mapa\n",
    "def pixel_to_map_coordinates(transform, col, row):\n",
    "    x, y = transform * (col, row)\n",
    "    return x, y\n",
    "\n",
    "# Abrir el archivo TIF\n",
    "with rasterio.open(input_path) as src:\n",
    "    # Leer todas las bandas y guardar los valores en una matriz\n",
    "    data = src.read()\n",
    "\n",
    "    # Obtener la transformación de coordenadas de píxeles a coordenadas de mapa\n",
    "    transform = src.transform\n",
    "\n",
    "    # Crear una lista vacía para almacenar los datos de cada polígono\n",
    "    polygons = []\n",
    "\n",
    "    # Iterar sobre cada banda y crear polígonos para cada píxel con valor distinto de cero\n",
    "    for i in range(src.count):\n",
    "        band_data = data[i, :, :]\n",
    "\n",
    "        for row in tqdm(range(band_data.shape[0])):\n",
    "            for col in range(band_data.shape[1]):\n",
    "                # Obtener el valor del píxel\n",
    "                value = band_data[row, col]\n",
    "\n",
    "                # Si el valor es cero, ignorar el píxel\n",
    "                if value > 0:\n",
    "                    #continue\n",
    "\n",
    "                    # Calcular las coordenadas de los cuatro vértices del polígono\n",
    "                    x1, y1 = pixel_to_map_coordinates(transform, col, row)\n",
    "                    x2, y2 = pixel_to_map_coordinates(transform, col + 1, row)\n",
    "                    x3, y3 = pixel_to_map_coordinates(transform, col + 1, row + 1)\n",
    "                    x4, y4 = pixel_to_map_coordinates(transform, col, row + 1)\n",
    "\n",
    "                    # Crear el polígono a partir de los vértices\n",
    "                    poly = Polygon([(x1, y1), (x2, y2), (x3, y3), (x4, y4)])\n",
    "\n",
    "                    # Agregar el polígono y su información a la lista de polígonos\n",
    "                    polygon_data = {\n",
    "                        'band': i+1,\n",
    "                        'value': value,\n",
    "                        'geometry': poly\n",
    "                    }\n",
    "                    polygons.append(polygon_data)\n",
    "                    \n",
    "# Crear un GeoDataFrame a partir de la lista de polígonos\n",
    "gdf = gpd.GeoDataFrame(polygons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the GeoDataFrame with colors based on the 'value' column\n",
    "gdf.plot(column='value', cmap='viridis', legend=True, figsize=(10, 10))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Map with Colors per Value Column')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pga_specifications = pd.read_excel(f\"{input_path2}\")  \n",
    "\n",
    "# dtype_mapping = {\n",
    "#     'Acceleration_min': float,\n",
    "#     'Acceleration_max': float, \n",
    "# }\n",
    "\n",
    "# pga_specifications = pd.read_csv(f\"{input_path2}\", dtype=dtype_mapping)\n",
    "pga_specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_interval(value, df, min_col, max_col):\n",
    "    for index, row in df.iterrows():\n",
    "        min_value = row[min_col]\n",
    "        max_value = row[max_col]\n",
    "        if min_value <= value and value < max_value:\n",
    "            return row['Instrumental_Intensity'], row['Acceleration_g'], row['Velocity_cmxs'], row['Perceived_shaking'], row['Potential_damage']\n",
    "        \n",
    "\n",
    "def gdf_interval_df(gdf, df, value_col, min_col, max_col):\n",
    "    '''\n",
    "    '''\n",
    "    gdf2 = gdf.copy()\n",
    "    resultado = gdf2.apply(lambda x: identify_interval(x[value_col], df, min_col, max_col), axis=1)\n",
    "    gdf2['Instrumental_Intensity'] = [x[0] for x in resultado]\n",
    "    gdf2['Acceleration_g'] = [x[1] for x in resultado]\n",
    "    gdf2['Velocity_cmxs'] = [x[2] for x in resultado]\n",
    "    gdf2['Perceived_shaking'] = [x[3] for x in resultado]\n",
    "    gdf2['Potential_damage'] = [x[4] for x in resultado]\n",
    "\n",
    "    return gdf2\n",
    "\n",
    "gdf2 = gdf_interval_df(gdf, pga_specifications, value_col='value', min_col='Acceleration_min', max_col='Acceleration_max')\n",
    "gdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2.to_file(output_path, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(gdf2['Instrumental_Intensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
