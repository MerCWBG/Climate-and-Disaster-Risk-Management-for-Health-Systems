{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import sys\n",
    "base_directory = \"/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/\"\n",
    "sys.path.append(f\"{base_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config_reader import ConfigReader, Logger\n",
    "from src.utils.utils import GeoDataFrameOperations, custom_preprocessing_infrastructure_return_file as custom_pre\n",
    "from src.utils.file_pocessor import FileLister, FileProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Logger\n",
    "log_directory = \"/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/data/nepal/outputs/log\"\n",
    "log_file_name = \"preprocessing\"\n",
    "logger = Logger(log_directory, log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Content of /Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/config/nepal/data_setup.yaml file successfully read\n"
     ]
    }
   ],
   "source": [
    "# Readding the configuration file to the preprocessing\n",
    "config_file_path = \"config/nepal/data_setup.yaml\"\n",
    "config_file_path = f\"{base_directory}{config_file_path}\"\n",
    "\n",
    "try:\n",
    "    config_data = ConfigReader.read_yaml_file(config_file_path)\n",
    "    # config_data = config_data['preprocessing']\n",
    "    txt_msg = \"Content of {} file successfully read\".format(config_file_path)\n",
    "    logger.info(txt_msg)\n",
    "except Exception as e:\n",
    "    txt_msg = f\"Error reading configuration file: {str(e)}\"\n",
    "    logger.error(txt_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write different types of messages to the log file\n",
    "# logger.info('Information message')\n",
    "# logger.warning('Warning message')\n",
    "# logger.error('Error message')\n",
    "# logger.critical('Critical message')\n",
    "# logger.debug('Debug message')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/data/nepal/outputs/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_files = f\"{base_directory}{config_data['output_files']}\"\n",
    "output_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'population'\n",
    "try :\n",
    "    population_task = config_data[attribute]\n",
    "except Exception as e:\n",
    "    population_task = None\n",
    "    txt_msg = f\"Atribute {str(e)} not found\"\n",
    "    logger.error(txt_msg)\n",
    "\n",
    "attribute_destinity = f\"{output_files}{attribute}/\"\n",
    "if not os.path.exists(attribute_destinity):\n",
    "    os.makedirs(attribute_destinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Processing population file: /Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/data/nepal/inputs/popu/nepal_npl_ct_popu_pop_sp_py_GHS_2023_p_u_Clipped_E2020_Nepal_54009.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5511/5511 [01:30<00:00, 60.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully file processed\n"
     ]
    }
   ],
   "source": [
    "# Processing Population task\n",
    "for task in population_task:\n",
    "    task_type = task['name']\n",
    "    input_path = f\"{base_directory}{task['source']}\"\n",
    "    txt_msg = f\"Processing population file: {input_path}\"\n",
    "    logger.info(txt_msg)\n",
    "    \n",
    "    # Transforming raster\n",
    "    try:\n",
    "        gdf = FileProcessor.read_tif(input_path, 'polygon')\n",
    "        gdf.columns = ['band', 'population', 'geometry']\n",
    "        gdf = gdf[['population', 'geometry']]\n",
    "        # gdf['geometry'] = gdf.geometry.centroid\n",
    "    except Exception as e:\n",
    "        txt_msg = f\"{str(e)}\"\n",
    "        logger.error(txt_msg)       \n",
    "    \n",
    "    # Saving file\n",
    "    try:\n",
    "        output_name = f'{task_type}.gpkg'\n",
    "        FileProcessor.save_to_geopackage(gdf, attribute_destinity, output_name)\n",
    "        txt_msg = f\"Successfully file processed\"\n",
    "        logger.info(txt_msg)\n",
    "    except Exception as e:\n",
    "        txt_msg = f\"{str(e)}\"\n",
    "        logger.error(txt_msg) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'infrastructures'\n",
    "try :\n",
    "    infrastructures_task = config_data[attribute]\n",
    "except Exception as e:\n",
    "    infrastructures_task = None\n",
    "    txt_msg = f\"Atribute {str(e)} not found\"\n",
    "    logger.error(txt_msg)\n",
    "\n",
    "attribute_destinity = f\"{output_files}{attribute}/\"\n",
    "if not os.path.exists(attribute_destinity):\n",
    "    os.makedirs(attribute_destinity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Processing population file: /Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/data/nepal/inputs/heal/nepal_npl_ct_heal_heal_sp_tab_NDRRNA_14022024.gpkg\n",
      "INFO: Successfully file processed\n",
      "INFO: Processing population file: /Users/johnbarrera/Documents/Projects/world_bank/Climate-and-Disaster-Risk-Management-for-Health-Systems/data/nepal/inputs/heal/nepal_npl_ct_heal_heal_sp_tab_NDRRNA_14022024.gpkg\n",
      "INFO: Successfully file processed\n"
     ]
    }
   ],
   "source": [
    "# Processing Infrastructure task\n",
    "for task in infrastructures_task:\n",
    "    task_type = task['name']\n",
    "    task_filter= task['filter']\n",
    "    input_path = f\"{base_directory}{task['source']}\"\n",
    "    \n",
    "    txt_msg = f\"Processing population file: {input_path}\"\n",
    "    logger.info(txt_msg)\n",
    "    \n",
    "    # Transforming raster\n",
    "    try:\n",
    "        gdf = FileProcessor.read_geopackage(input_path)\n",
    "        if task_filter is not None:\n",
    "            for filter_str in task_filter:\n",
    "                gdf = gdf.query(filter_str)\n",
    "                gdf = gdf.reset_index(drop=True)\n",
    "    except Exception as e:\n",
    "        txt_msg = f\"{str(e)}\"\n",
    "        logger.error(txt_msg) \n",
    "            \n",
    "    # Saving file\n",
    "    try:\n",
    "        output_name = f'{task_type}_infrastructure.gpkg'\n",
    "        FileProcessor.save_to_geopackage(gdf, attribute_destinity, output_name)\n",
    "        txt_msg = f\"Successfully file processed\"\n",
    "        logger.info(txt_msg)\n",
    "    except Exception as e:\n",
    "        txt_msg = f\"{str(e)}\"\n",
    "        logger.error(txt_msg) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'hazards'\n",
    "try :\n",
    "    hazards_task = config_data[attribute]\n",
    "except Exception as e:\n",
    "    hazards_task = None\n",
    "    txt_msg = f\"Atribute {str(e)} not found\"\n",
    "    logger.error(txt_msg)\n",
    "\n",
    "attribute_destinity = f\"{output_files}{attribute}/\"\n",
    "if not os.path.exists(attribute_destinity):\n",
    "    os.makedirs(attribute_destinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: The file contents periodical records for earthquakes\n",
      "INFO:  ==> Processing period 975: pga_975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:01<00:00, 255.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully file processed\n",
      "INFO:  ==> Processing period 2475: pga_2475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:01<00:00, 258.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully file processed\n",
      "INFO:  ==> Processing period 475: pga_rp475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:01<00:00, 257.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully file processed\n",
      "INFO:  ==> Processing period 1500: pga_1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:01<00:00, 236.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully file processed\n",
      "\n",
      "INFO: The file contents historical records for landslides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:01<00:00, 228.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully file processed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Processing Hazards task\n",
    "for task in hazards_task:\n",
    "    task_name = task['name']\n",
    "    task_historical = task['historical']\n",
    "    return_periods = task['return_periods']\n",
    "    substantial_damage = task['substantial_damage']\n",
    "    complete_destruction = task['complete_destruction']\n",
    "    input_path = f\"{base_directory}{task['source']}\"\n",
    "    \n",
    "\n",
    "    if task_historical:\n",
    "        txt_msg = f\"The file contents historical records for {task_name}\"\n",
    "        logger.info(txt_msg)\n",
    "        \n",
    "        files = FileLister.list_files(input_path)\n",
    "        valid_files = files\n",
    "        # Read valid files \n",
    "        for file in valid_files:\n",
    "            try:     \n",
    "                file_name = file[0]\n",
    "                file_path = file[1]  \n",
    "                # Transforming raster\n",
    "                gdf = FileProcessor.read_tif(file_path, 'polygon')\n",
    "                # Column damage generation\n",
    "                gdf = GeoDataFrameOperations.calculate_damage(gdf, substantial_damage, complete_destruction)\n",
    "            except Exception as e:\n",
    "                txt_msg = f\"Error: '{e}'\"\n",
    "                logger.error(txt_msg)\n",
    "            # Saving file\n",
    "            try:\n",
    "                output_name = f'{task_name}_historical.gpkg'\n",
    "                FileProcessor.save_to_geopackage(gdf, attribute_destinity, output_name)\n",
    "                txt_msg = f\"Successfully file processed\"\n",
    "                logger.info(txt_msg)\n",
    "            except Exception as e:\n",
    "                txt_msg = f\"{str(e)}\"\n",
    "                logger.error(txt_msg) \n",
    "        \n",
    "        pass\n",
    "    else:\n",
    "        txt_msg = f\"The file contents periodical records for {task_name}\"\n",
    "        logger.info(txt_msg)\n",
    "        files = FileLister.list_files(input_path)\n",
    "        \n",
    "        valid_files = custom_pre.append_period_to_filelist(files, return_periods)\n",
    "        # Read valid files \n",
    "        for file in valid_files:\n",
    "            file_name = file[0]\n",
    "            file_path = file[1]\n",
    "            file_period = file[2]\n",
    "            txt_msg = f\" ==> Processing period {file_period}: {file_name}\"\n",
    "            logger.info(txt_msg)\n",
    "            try:      \n",
    "                # Transforming raster\n",
    "                gdf = FileProcessor.read_tif(file_path, 'polygon')\n",
    "                # Column damage generation\n",
    "                gdf = GeoDataFrameOperations.calculate_damage(gdf, substantial_damage, complete_destruction)\n",
    "            except Exception as e:\n",
    "                txt_msg = f\"Error: '{e}'\"\n",
    "                logger.error(txt_msg)         \n",
    "            # Saving file\n",
    "            try:\n",
    "                output_name = f'{task_name}_period_{file_period}.gpkg'\n",
    "                FileProcessor.save_to_geopackage(gdf, attribute_destinity, output_name)\n",
    "                txt_msg = f\"Successfully file processed\"\n",
    "                logger.info(txt_msg)\n",
    "            except Exception as e:\n",
    "                txt_msg = f\"{str(e)}\"\n",
    "                logger.error(txt_msg) \n",
    "    print()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "                \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
